{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "w6K7xa23Elo4",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "PIIx-8_IphqN",
        "r2jJGEOYphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "-Kee-DAl2viO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaRansing/Ted_talks_views_prediction/blob/main/Ted_talk_view_prediction_project_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -   **TED Talk Views Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aimed to build a predictive model that can accurately predict the number of views of TED talks videos uploaded on the TEDx website. The dataset contained over 4,000 TED talks including transcripts in many languages. The data was explored and preprocessed to handle missing values, outliers, and categorical variables. Feature engineering was performed to extract additional information from the data, such as the length of the talk and the number of speakers.\n",
        "\n",
        "Several regression algorithms were evaluated to determine which model would provide the best predictions. Linear regression, Ridge regression, and Lasso regression were applied to the dataset. The performance of these models was compared using various evaluation metrics, including mean absolute error, mean squared error, and root mean squared error. The results showed that Lasso regression outperformed the other models, with the lowest mean squared error and root mean squared error.\n",
        "\n",
        "Feature selection was also performed using the Lasso regression model to identify the most important features that contribute to the prediction of the number of views. The selected features were the duration of the talk, the number of views, the number of comments, and the number of languages the talk was translated into.\n",
        "\n",
        "Overall, this project demonstrated that it is possible to build a reliable predictive model that can accurately predict the number of views of TED talks videos uploaded on the TEDx website. "
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/MonaRansing/Ted_talks_views_prediction.git"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TED is devoted to spreading powerful ideas on just about any topic. These datasets contain over 4,000 TED talks including transcripts in many languages. Founded in 1984 by Richard Salman as a nonprofit organization that aimed at bringing experts from the fields of Technology, Entertainment and Design together, TED Conferences have gone on to become the Mecca of ideas from virtually all walks of life. As of 2015, TED and its sister TEDx chapters have published more than 2000 talks for free consumption by the masses and its speaker list boasts of the likes of AI Gore, Jimmy Wales, Shahrukh Khan and Bill Gates. The main objective is to build a predictive model, which could help in predicting views of the videos uploaded on the TEDx website. "
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Data visualisation libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import stats\n",
        "\n",
        "# preprocessing libraries\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "# model selection libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# machine learning libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
        "from sklearn.ensemble import VotingRegressor,StackingRegressor\n",
        "\n",
        "\n",
        "# metrics libraries\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# data visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# dataetime library \n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "# for remove Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "\n",
        "# pipeline libraries\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import ast\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "# google drive mounted \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset reading using read_csv\n",
        "ted_talk_dataset = '/content/drive/MyDrive/Almabetter/Data Science/dataset/data_ted_talks.csv'\n",
        "df = pd.read_csv(ted_talk_dataset)"
      ],
      "metadata": {
        "id": "zPK00kIRGB-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# first 5 rows \n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last five rows\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "Ep1oyXqyGXkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give dataset has **4005 rows** and **19 columns**."
      ],
      "metadata": {
        "id": "-EG4wc77G0Kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding dataset information\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making cpoy of dataset\n",
        "df1 = df.copy()\n",
        "df1"
      ],
      "metadata": {
        "id": "2hXKs6gOI8cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_values= df1.duplicated().value_counts()\n",
        "duplicate_values"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given dataset there are no any duplicate values."
      ],
      "metadata": {
        "id": "zVFHaAelJcmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df1.isnull().sum().sort_values(ascending=False)[:5]\n",
        "missing_values"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "columns = ['comments','occupation','about_speakers','all_speakers','recorded_date']\n",
        "missing_values = [655,522,503,4,1]\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(x=columns, y=missing_values, data=df1, palette='husl')\n",
        "plt.title('Visualisation of missing values', fontsize = 20)\n",
        "plt.xlabel('Name of column', fontsize = 15)\n",
        "plt.ylabel('Count of missing Values', fontsize = 15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The given dataset has 4005 columns and 19 rows. There are no any duplicate value.Dataset has 5 columns which have missing values and those columns are commnets,occupation, about_speakers, all_speakers, recorded_date.**"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df1.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df1.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "C5MXGNn8vo-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "kktA8FS9wzzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **talk_id:** A unique identifier for each TED Talk video.**(Numerical)**\n",
        "\n",
        "* **title:** The title of the talk.**(Categorical)**\n",
        "\n",
        "* **speaker_1:** The primary speaker for the talk.**(Categorical)**\n",
        "\n",
        "* **all_speakers:** A list of all the speakers for the talk.**(Categorical)**\n",
        "\n",
        "* **occupations:** The occupations of the speakers.**(Categorical)**\n",
        "\n",
        "* **about_speakers:** Information about the speakers, such as their backgrounds and expertise.**(Categorical)**\n",
        "\n",
        "* **views:** The number of views the video has received.**(Numerical)**\n",
        "\n",
        "* **recorded_date:** The date the talk was recorded.**(Datetime)**\n",
        "\n",
        "* **published_date:** The date the talk was published on the TED Talks YouTube channel.**(Datetime)**\n",
        "\n",
        "* **event:** The name of the TED event where the talk was given.**(Categorical)**\n",
        "\n",
        "* **native_lang:** The language the talk was given in.**(Categorical)**\n",
        "\n",
        "* **available_lang:** The languages the talk is available in.**(Categorical)**\n",
        "\n",
        "* **comments:** The number of comments on that video.**(Numerical)**\n",
        "\n",
        "* **duration:** The length of the video.(in sec.)**(Numerical)**\n",
        "\n",
        "* **topics:** The topics covered in the talk.**(Categorical)**\n",
        "\n",
        "* **related talks:** Other TED Talks that are related to this talk.**(Categorical)**\n",
        "\n",
        "* **url:** The URL of the video.**(Categorical)**\n",
        "\n",
        "* **description:** A brief description of the talk.**(Categorical)**\n",
        "\n",
        "* **transcript:** A transcript of the talk.**(Categorical)**"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the given dataset there are three columns which have numerical values and \n",
        "those columns are talk_id, views,comments and duration.\n",
        "* 13 columns which have categorical values and those columns are title, speaker_1,all_speakers,occupation,about_speakers,event,native_lang,available_lang,topics,related_talks,url,description,transcript.\n",
        "* 2 columns which have datetime values and those columns are recorded_date,published_date.\n"
      ],
      "metadata": {
        "id": "VVEF0IjfxcMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(df1.apply(lambda col: col.unique()))"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# description of dataset\n",
        "df1.describe().T"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot to visualize outliers in comment column\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.boxplot(x=df1['comments'],data=df1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SX-g0HbQ0sCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot to visualize outliers in views column\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.boxplot(x=df1['views'],data=df1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7l1QWUS_2ODl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot to visualize outliers in duration column.\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.boxplot(x=df1['duration'],data=df1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tSfAozXbzsxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The minimum value of views is 0.\n",
        "* The minimum value of comments is 0.\n",
        "* There are outliers in columns views, comments and duration."
      ],
      "metadata": {
        "id": "ZmTXdX8HzuYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the row where column comments have 0 value\n",
        "df1[df1['comments']==0]"
      ],
      "metadata": {
        "id": "cbODkizL3Nmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In given dataset there are 2 rows which have 0 value in comment column.**"
      ],
      "metadata": {
        "id": "MTrq3x874BGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the row where column views have 0 value\n",
        "df1[df1['views']==0]"
      ],
      "metadata": {
        "id": "Dbgs7eph4Pu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are 6 rows which have 0 value in views column and comment columns have NaN.\n",
        "* In dataset 6 NaN values are present in comments columns. So we have to fill that value also."
      ],
      "metadata": {
        "id": "bmJ6M6D_4qFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.describe(include='O').T"
      ],
      "metadata": {
        "id": "9fmkyipL5frz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two columns in above dataset which have same containt so we have to drop one of them."
      ],
      "metadata": {
        "id": "qUiT5yJH5tNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling The missing values.\n",
        "missing_values = df1.isnull().sum().sort_values(ascending=False)[:5]\n",
        "missing_values"
      ],
      "metadata": {
        "id": "1vj3L6-pK-D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_columns=['occupations','about_speakers','all_speakers']\n",
        "for columns in null_columns:\n",
        "  df1[columns].fillna('other',inplace=True)"
      ],
      "metadata": {
        "id": "FgkfKBYcL70A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['comments'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "apUlMgonQQ0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum().sort_values"
      ],
      "metadata": {
        "id": "ujNn_LXSQeYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chane the datatype of some columns\n",
        "df1 = df1.astype({'talk_id':'int32','views':'int32','comments':'int32','duration':'int32',})\n",
        "df1['recorded_date']=pd.to_datetime(df1['recorded_date'])\n",
        "df1['published_date']=pd.to_datetime(df1['published_date'])"
      ],
      "metadata": {
        "id": "02kmfLcFSZHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "fgNVySvDTkuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop all_speaker column because it is duplicate of speakar_1 and also drop url and talk_id columns because they are not required.\n",
        "df1.drop(['all_speakers', 'url', 'talk_id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "qqxL-W_MTwVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# speaker_1 is renamed as speakers\n",
        "df1.rename(columns={\"speaker_1\":\"speakers\"}, inplace=True)"
      ],
      "metadata": {
        "id": "XGYSsuDhXNlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1= df1[df1['views']!=0]"
      ],
      "metadata": {
        "id": "qqS0HtRHZI3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((df1['views']==0).sum())"
      ],
      "metadata": {
        "id": "33VLiooDZOhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "_YDHU3BbaWeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In given dataset there are four columns 'comments','occupation','about_speaker','all_speakers' have missing values. So In these columns values are fill using fillna() function. Comments column is fill with 0 value and other three columns are fill with 'other'.\n",
        "* Some columns like talk_id, views, comment, duration, recorded_date, published_date need to be change their datatype. So datatype is changed.\n",
        "* Three columns 'all_speakers','url','talk_id' these columns do not required for analysis so these columns are droped.\n",
        "* 'views' column have six rows with 0 value and TED talk videos have 0 views is impossible. So those rows are droped from dataset."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dependent variable in dataset is \"views\". So in dataset there are some columns like 'occupation','about_speakers','related_talks','description','transcript' are not corelated with dependent varible. So it is better to remove from dataset."
      ],
      "metadata": {
        "id": "kzNeob7ueyx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove unwanted columns\n",
        "df1.drop(['occupations','about_speakers','related_talks','description','transcript'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "5VvbQsH9fG8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Which are first 10 popular TED talks based on title,speaker and views?\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-gXoU7LMgjVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "popular_talk = df1[['title','speakers','views']].sort_values('views', ascending=False)[0:10]\n",
        "popular_talk"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(x=popular_talk['speakers'],y=popular_talk['views'],data=popular_talk)\n",
        "plt.title('Most popular TED talks', fontsize=20)\n",
        "plt.ylabel('Views', fontsize=15)\n",
        "plt.xlabel('Speakers of popular TED talks', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vacxJJozifzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose this plot beacause barplot is easy to read and understand."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart I found following insights:\n",
        "* The speaker Sir Ken Robinson who talks on \"Do schools kill creativity?\" topic and this topic is most popular topic and has 65051954 views.\n",
        "* The speaker Amy Cuddy who talks on \"Your body language may shape who you are\" topic and this topic is second most popular topic and has 57074270 views.  \t"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Which are top 10 most popular speakers based on views? "
      ],
      "metadata": {
        "id": "U-llFvpCmHCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "popular_speakrs = df1.groupby('speakers')['views'].sum().nlargest(10).reset_index()\n",
        "popular_speakrs\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(x=popular_speakrs['speakers'],y=popular_speakrs['views'],data=popular_speakrs)\n",
        "plt.title('Top 10 speakers', fontsize=20)\n",
        "plt.ylabel('Views', fontsize=15)\n",
        "plt.xlabel('Speakers', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q9y5qxCzn0AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose this plot beacause barplot is easy to read and understand."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Alex Gendler is most popular speaker and followed by Sir ken Robinson.\n",
        "* Alex Gendler's video has 117619583 views and second most popular speaker Sir ken Robinson's video has 84380518 views.\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.skew()"
      ],
      "metadata": {
        "id": "Zp8wVOhZxwM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   The views column has **positive skewness** of **8.104312** which which suggests that the distribution of the views variable is **highly skewed to the right**. This means that there are a few videos with a very large number of views, while the majority of videos have a relatively small number of views.\n",
        "2.   The comments column has a **positive skewness** of **9.158308**, which indicates that the distribution of the comments variable is also **highly skewed to the right**. Similar to the views variable, there are a few videos with a very large number of comments, while the majority of videos have a relatively small number of comments.\n",
        "3.  The duration column has a **positive skewness** of **1.186224**, which suggests that the distribution of the duration variable is also slightly skewed to the right, but to a lesser extent than the views and comments variables. This means that the majority of videos have a shorter duration, while a few videos have a longer duration.\n",
        "4. So I focuse on numerical columns, deal with outliers and null values and then check skewness of the columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "aL26D0-qzKJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Dealing with outliers in columns comments, viwes and Duration.**"
      ],
      "metadata": {
        "id": "jW8VUAoOxp8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking correlation with view column\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.scatterplot(x='comments', y=\"views\", data = df1, color = 'green')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above scatterplot it is clear that comments and views are right skewwd and they have somehwat similar distribution and highly right skewed distribution means high outliers.\n"
      ],
      "metadata": {
        "id": "q-GsYfgDJWwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check distrubution of comment column\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.distplot(df1['comments'], color='green')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TPKcrxr5KD8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove outliers of comments column\n",
        "df1.drop(df1[df1['comments']>1000].index, inplace=True)"
      ],
      "metadata": {
        "id": "v7qEHnqNOneA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "Q0b8VWXMOzma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill null values with median of column\n",
        "df1['comments']=df1['comments'].replace(0, np.nan)\n",
        "df1['comments'].fillna(df1['comments'].median(),axis = 0, inplace=True)"
      ],
      "metadata": {
        "id": "NqPIxoLGO2Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use median beacause while dealing with outliers insted of mean median is better."
      ],
      "metadata": {
        "id": "RVZBJG12Qwza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distplot after removal of outliers\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(df1['comments'], color ='green')"
      ],
      "metadata": {
        "id": "JEwFA3W1Pn91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now after removal of outliers column comments are right skewd."
      ],
      "metadata": {
        "id": "0FuJB42sRIin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check distribution of duration column\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.distplot(df1['duration'], color='green')"
      ],
      "metadata": {
        "id": "Scl1cTTvCMUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check correlation of duration and views using scatter plot\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.scatterplot(x='duration', y='views', data=df1, color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PuLErINDCgZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that duration and views are not correlated with each other. Na duration column has outliers."
      ],
      "metadata": {
        "id": "IW2G2Kz_DAVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check outliers using boxplot in duration and views column\n",
        "columns = ['views','duration']\n",
        "n = 1\n",
        "plt.figure(figsize=(14,7))\n",
        "\n",
        "for i in columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(df1[i], orient='h')\n",
        "  plt.title(i)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "FbUpXVnFC47x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier traetment\n",
        "columns = ['views','duration']\n",
        "\n",
        "for i in columns:\n",
        "  iqr = df1[i].quantile(0.75)-df1[i].quantile(0.25)\n",
        "  df1[i]=df1[i].mask(df1[i]>(df1[i].quantile(0.75)+1.5*iqr), df1[i].mean())"
      ],
      "metadata": {
        "id": "Fe70PuMVFqeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['views','duration']\n",
        "n = 1\n",
        "plt.figure(figsize=(14,7))\n",
        "\n",
        "for i in columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.boxplot(df1[i], orient='h')\n",
        "  plt.title(i)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "q5LFvBERGSgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after outlier traetment distribution graph of columns views and duration\n",
        "fig,axs=plt.subplots(1,2,figsize=(14,7))\n",
        "sns.distplot(df1['views'], color='green', ax=axs[0])\n",
        "axs[0].set_title('Distribution of views')\n",
        "\n",
        "sns.distplot(df1['duration'], color='green', ax=axs[1])\n",
        "axs[1].set_title('Distribution of Duration')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AMDyS4YKGXuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* After filling outliers with mean views column is little bit right skewed with normal distribution and for duration column are bi-model type distribution."
      ],
      "metadata": {
        "id": "ThfOv_OnHxC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.skew()"
      ],
      "metadata": {
        "id": "ND1i9LMdHvjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Check speaker popularity."
      ],
      "metadata": {
        "id": "zxz_erKKJHC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# create a new column 'spaker popularity\n",
        "df1['speaker_popularity'] = \"\"\n",
        "df1.loc[df1['views']<=500000, 'speaker_popularity'] = 'not_popular'\n",
        "df1.loc[(df1['views']> 500000) & (df1['views'] <= 1500000), 'speaker_popularity'] = 'avg_popular'\n",
        "df1.loc[(df1['views']>1500000) & (df1['views']<=2500000), 'speaker_popularity'] = 'popular'\n",
        "df1.loc[(df1['views']>2500000) & (df1['views']<=3500000), 'speaker_popularity'] = 'high_popular'\n",
        "df1.loc[df1['views']>3500000, 'speaker_popularity'] = 'extreme_popular'"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(data=df1, x='speaker_popularity', y='comments',\n",
        "            order=['not_popular','avg_popular','popular','high_popular','extreme_popular'])\n",
        "plt.title(\"Speakers popularity according to comments\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mqj7TmvqLIqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* speaker_popularity and comments column has strong correlation with each other means comments going to increase speaker_popularity also foing to increase."
      ],
      "metadata": {
        "id": "LEPYZ0FyQwGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Check video rating"
      ],
      "metadata": {
        "id": "FxtNSRegRFqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# create a new column video_rating\n",
        "df1['video_rating'] = \"\"\n",
        "df1.loc[df1['comments']<=50, 'video_rating'] = 1\n",
        "df1.loc[(df1['comments']>50) & (df1['comments']<=100), \"video_rating\"] = 2\n",
        "df1.loc[(df1['comments']>100) & (df1['comments']<=200), \"video_rating\"] = 3\n",
        "df1.loc[(df1['comments']>200) & (df1['comments']<=300), \"video_rating\"] = 4\n",
        "df1.loc[df1['comments']>300, \"video_rating\"] = 5"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_counts = df1['video_rating'].value_counts().sort_values(ascending=False)\n",
        "rating_counts"
      ],
      "metadata": {
        "id": "8igSAF3MUTiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "rating_counts.plot(kind='bar', color='green')\n",
        "plt.title('Distribution of Video Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b3A_rRAyUkqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this plot is easy to understand. "
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above barplot I get insight is there are 1385 videos which have rating 2 means those values have comments between 50-100. "
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Chek available languages"
      ],
      "metadata": {
        "id": "_5xjgliD3OQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 6 visualization code\n",
        "df1[\"available_langauges\"] = df1[\"available_lang\"].apply(lambda x: len(x))\n",
        "pd.DataFrame(df1[\"available_langauges\"])"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.distplot(df1[\"available_langauges\"], color='green')"
      ],
      "metadata": {
        "id": "J5kp_D8R4I2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distplot for available langauges is slightly right skewed and in the middle of plot there are more values."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Published Date"
      ],
      "metadata": {
        "id": "EBuZ1hSQAuz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making seperate column for day, month, and year\n",
        "df1['published_year'] = df1[\"published_date\"].dt.year\n",
        "df1['published_month'] = df1[\"published_date\"].dt.month\n",
        "df1['published_day'] = df1[\"published_date\"].dt.day_name()\n",
        "\n",
        "# storing weekdays in order of numbers from 0 to 6 value\n",
        "weekdays = {'Sunday':0, 'Monday':1,'Tuseday':2, 'Wednesday':0, 'Thursday':4, 'Friday': 5,'Saturday':6}\n",
        "\n",
        "# making nw column which have informaton of day number\n",
        "\n",
        "df1[\"published_daynumb\"] = df1[\"published_day\"].map(weekdays)"
      ],
      "metadata": {
        "id": "SIoRVIQzAtZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.sample()"
      ],
      "metadata": {
        "id": "T6BLyYMCCdJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Check different events of TED upto year 2013."
      ],
      "metadata": {
        "id": "8tiH482z_h-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "TED_events = df1[\"event\"].value_counts().head(10).reset_index().rename(columns={'index': 'events', 'event': 'Counts'})\n",
        "TED_events"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(x=TED_events['events'], y=TED_events['Counts'], order=TED_events['events'])\n",
        "plt.title('TED events count', fontsize=20)\n",
        "plt.ylabel('Counts', fontsize=15)\n",
        "plt.xlabel('Events', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_TUgECk5DBni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new column TED event type by using existing column event\n",
        "ted_categories = ['TED-ED', 'TEDx','TED','TEDGlobal','TEDSummit','TEDWomen','TED Residency']\n",
        "\n",
        "df1['TEDevent_type'] = df1['event'].map(lambda x : \"TEDx\" if x[0:4] == \"TEDx\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"TED-ED\" if x[0:4] == \"TED-ED\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"TED\" if x[0:4] == \"TED2\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"TEDGlobal\" if x[0:4] == \"TEDG\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"TEDWomen\" if x[0:4] == \"TEDW\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"TEDSummit\" if x[0:4] == \"TEDS\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"TED Residency\" if x[0:13] == \"TED Residency\" else x)\n",
        "df1['TEDevent_type'] = df1['TEDevent_type'].map(lambda x : \"Other TED\" if x not in ted_categories else x)"
      ],
      "metadata": {
        "id": "QClN-80ps1or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.sample(1)"
      ],
      "metadata": {
        "id": "QFH2fMjPur1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEDevent_type = pd.DataFrame(df1['TEDevent_type'].value_counts()).reset_index().rename(columns={'index': 'TEDevent_type', 'TEDevent_type': 'Counts'})\n",
        "TEDevent_type"
      ],
      "metadata": {
        "id": "9xc3QNfIu386"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(x=TEDevent_type['TEDevent_type'], y=TEDevent_type['Counts'], order=TEDevent_type['TEDevent_type'])\n",
        "plt.title('Barplot of TEDevent type', fontsize=20)\n",
        "plt.ylabel('Counts', fontsize=15)\n",
        "plt.xlabel('TEDevent type', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8KoyFvBpvSMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Becuase barplot is easy to understand and we can read that plot so easily."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that ted events which are other TED have highest number which is 1231. "
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8) Topics of TED talk"
      ],
      "metadata": {
        "id": "jg9X4ifcFC4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "df_1 = df1.copy()\n",
        "\n",
        "df_1['topics'] = df_1['topics'].apply(lambda x: ast.literal_eval(x))\n",
        "s = df_1.apply(lambda x: pd.Series(x['topics']),axis=1).stack().reset_index(level=1, drop=True)\n",
        "s.name = 'topic'\n",
        "\n",
        "df_1 = df_1.drop('topics', axis=1).join(s)"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.head()"
      ],
      "metadata": {
        "id": "b6kh6-A0FwRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Popular_topics = pd.DataFrame(df_1['topic'].value_counts()).reset_index()\n",
        "Popular_topics.columns=['topic','TEDtalks']"
      ],
      "metadata": {
        "id": "pF6T-5hVG_Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "sns.barplot(x=\"topic\", y=\"TEDtalks\", data=Popular_topics.head(10))\n",
        "plt.title('Popular topics in TED talk', fontsize=20)\n",
        "plt.ylabel('Topics', fontsize=15)\n",
        "plt.xlabel('TEDtalks', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qJRoqjorHm3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because visualization becomes easy when we use barplot."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* First 10 Popular TED talks videos are based on science, technology, culture, TEDx, TED-ED, global issues, socirty, design, social change and animation\n",
        "* Within above 10 topics science and technology are most popular."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the stacked bar charts of top 8 topics over the year and check trend\n",
        "\n",
        "pop_theme_talks = df_1[(df_1['topic'].isin(Popular_topics.head(12)['topic'])) & (df_1['topic'] != ('TEDx','TED-Ed'))]\n",
        "pop_theme_talks['published_year'] = pop_theme_talks['published_year'].astype('int')\n",
        "pop_theme_talks = pop_theme_talks[pop_theme_talks['published_year'] > 2008]\n",
        "\n",
        "\n",
        "themes = list(Popular_topics.head(10)['topic'])\n",
        "themes.remove('TEDx')\n",
        "themes.remove('TED-Ed')\n",
        "\n",
        "ctab = pd.crosstab([pop_theme_talks['published_year']], pop_theme_talks['topic']).apply(lambda x: x/x.sum(), axis=1)\n",
        "ctab[themes].plot(kind='bar', stacked=True, colormap='plasma', figsize=(12,8)).legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cE4IRU5Dm1PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Selection**"
      ],
      "metadata": {
        "id": "u_SC9l5MnYcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.sample(2)"
      ],
      "metadata": {
        "id": "4YlzfhwKKOT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(labels = [\"speakers\", \"title\", \"recorded_date\", \"published_date\", \"event\", \"native_lang\", \"available_lang\",\"topics\"],axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "q89TLXiqBR0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.sample(1)"
      ],
      "metadata": {
        "id": "6FEcNSkhoFJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "b0n9ZPLEjRPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.astype({'comments':'int64', 'views':'int64','video_rating':'int64'})\n",
        "\n",
        "df1 = df1.astype({'speaker_popularity': 'category','published_day': 'category','TEDevent_type':'category'})"
      ],
      "metadata": {
        "id": "VWZPCH9bA3dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "jmYcklqdLYh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "correlmap = df1.corr()\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.heatmap(correlmap, annot=True)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to know the correlation between columns in a given data and we want effective visualization then hetmap is beat choice because we can uderstand easily."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependent column in given dataset is views so the columns comments and avaliable_ langauges are most correlated with views column."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check Multicollinearity and Remove**\n"
      ],
      "metadata": {
        "id": "bxpIAcFyYJpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select numeric columns\n",
        "numeric_columns = df1.select_dtypes(include=['int64','int32','float32','float64']).drop(['views'],axis=1)\n",
        "\n",
        "# replace infinite and NaN values with appropriate values\n",
        "numeric_columns = numeric_columns.replace([np.inf, -np.inf], np.nan)\n",
        "numeric_columns = numeric_columns.fillna(numeric_columns.mean())\n",
        "\n",
        "# calculate VIF for each feature\n",
        "vif = pd.DataFrame()\n",
        "vif['VIF Factor'] = [variance_inflation_factor(numeric_columns.values, i) for i in range(numeric_columns.shape[1])]\n",
        "vif['features'] = numeric_columns.columns\n",
        "print(vif)\n"
      ],
      "metadata": {
        "id": "eMFkNC76f8v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(['published_year','published_month','video_rating'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "aXAShF_so1ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select numeric columns\n",
        "numeric_columns = df1.select_dtypes(include=['int64','int32','float32','float64']).drop(['views'],axis=1)\n",
        "\n",
        "# replace infinite and NaN values with appropriate values\n",
        "numeric_columns = numeric_columns.replace([np.inf, -np.inf], np.nan)\n",
        "numeric_columns = numeric_columns.fillna(numeric_columns.mean())\n",
        "\n",
        "# calculate VIF for each feature\n",
        "vif = pd.DataFrame()\n",
        "vif['VIF Factor'] = [variance_inflation_factor(numeric_columns.values, i) for i in range(numeric_columns.shape[1])]\n",
        "vif['features'] = numeric_columns.columns\n",
        "print(vif)"
      ],
      "metadata": {
        "id": "2TrCS7-CpBh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.sample(1)"
      ],
      "metadata": {
        "id": "Jc66cryVpGF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt = PowerTransformer()\n",
        "df1['views'] = pt.fit_transform(pd.DataFrame(df1['views']))"
      ],
      "metadata": {
        "id": "eWwk8H9gpOWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.skew()"
      ],
      "metadata": {
        "id": "zBPw3fRapiJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "8Wj3nvp-2gRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = {'published_daynumb':0}\n",
        "\n",
        "df1 = df1.fillna(value=values)"
      ],
      "metadata": {
        "id": "Iw310Y1h2naX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "Nx7SODS-20OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.drop(columns=['views'])\n",
        "y = df1['views']"
      ],
      "metadata": {
        "id": "OQIJ4GgopvLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "0nfOP8kyp_9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "qdw-b46UqFLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state = 0)"
      ],
      "metadata": {
        "id": "7cP2Lxn_-O6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "zVxC6QQz-4Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, linear_model, metrics"
      ],
      "metadata": {
        "id": "fR3SynCq1ITE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = linear_model.LinearRegression()"
      ],
      "metadata": {
        "id": "-NlL_oNoBEB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.sample(2)"
      ],
      "metadata": {
        "id": "J2LURnq1_n_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step1 = ColumnTransformer(transformers=[\n",
        "    ('col_tnf', StandardScaler(),[0,1,3,5]),\n",
        "    ('col_tnf1', PowerTransformer(),[0,1,3]),\n",
        "    ('col_tnf2', OneHotEncoder(sparse=False, drop='first'),[4,6]),\n",
        "    ('col_tnf3', OrdinalEncoder(categories=[['not_popular','avg_popular','popular','high_popular','extreme_popular']]),[2])\n",
        "],remainder='passthrough')\n",
        "\n",
        "\n",
        "\n",
        "# display pipeline\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')"
      ],
      "metadata": {
        "id": "0C6LRbnoB5Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply LinearRegression algorithm as step2\n",
        "\n",
        "step2 = LinearRegression()\n",
        "\n",
        "\n",
        "# make pipeline\n",
        "pipe1 = Pipeline([\n",
        "    ('step1',step1),\n",
        "    ('step2',step2)\n",
        "])\n",
        "\n",
        "# fit the pipeline on training dataset\n",
        "pipe1.fit(X_train,y_train)\n",
        "\n",
        "# predict the train and test dataset \n",
        "y_pred_train = pipe1.predict(X_train)\n",
        "y_pred = pipe1.predict(X_test)\n",
        "\n",
        "# display pipeline diagram\n",
        "display(pipe1)\n",
        "\n",
        "# LinearRegression model all output scores\n",
        "print('\\033[1mTraining data R2 and Adjusted R2 Score\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('R2 score',r2_score(y_train,y_pred_train))\n",
        "print('Adjusted R2 score', (1-(1-r2_score(y_train,y_pred_train))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1))))\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mTesting data R2 and Adjusted R2 Score\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('R2 score',r2_score(y_test,y_pred))\n",
        "print('Adjusted R2 score', (1-(1-r2_score(y_test,y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))))\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mThe performance metrics\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('MAE',mean_absolute_error(y_test,y_pred))\n",
        "print('MSE',mean_squared_error(y_test,y_pred))\n",
        "print('RMSE',np.sqrt(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "33qJu0taCbv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the figure\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(y_pred)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No. of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JQUpBKPt7AqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observations**"
      ],
      "metadata": {
        "id": "BjLg1eu1NkUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Training data R2 and Adjusted R2 Score is 0.8872985205276127\n",
        "0.8870319066863465 respectively.\n",
        "\n",
        "* Testing data R2 and Adjusted R2 Score is 0.8849387907523739\n",
        "0.8841185988330935 respectively.\n",
        "\n",
        "* The performance metrics are:-\n",
        "\n",
        "    **MAE** 0.27380534823783437\n",
        "\n",
        "    **MSE** 0.11420981723987313\n",
        "\n",
        "    **RMSE** 0.33794943000377015\n"
      ],
      "metadata": {
        "id": "gMreyW2GNs4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply RidgeRegression algorithm with hyperparameter tuning as step2\n",
        "\n",
        "\n",
        "# giving parameters\n",
        "parameters = {'alpha': [1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,3,5,8,12,15,18,21,25]}\n",
        "\n",
        "# we use gridsearchCV because the dataset is not that big so we use this not RandomizedSearchCV\n",
        "Reg_ridge = GridSearchCV(Ridge(), parameters, cv=10)                             \n",
        "\n",
        "step2 = Reg_ridge\n",
        "\n",
        "# make pipeline\n",
        "pipe2 = Pipeline([\n",
        "    ('step1',step1),\n",
        "    ('step2',step2)\n",
        "])\n",
        "\n",
        "# fit the pipeline on training dataset\n",
        "pipe2.fit(X_train,y_train)\n",
        "\n",
        "# predict the train and test dataset \n",
        "y_pred_train = pipe2.predict(X_train)\n",
        "y_pred = pipe2.predict(X_test)\n",
        "\n",
        "# display pipeline diagram\n",
        "display(pipe2)\n",
        "\n",
        "# Ridge Regression model all output scores\n",
        "print('\\033[1mTraining data R2 and Adjusted R2 Score\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('R2 score',r2_score(y_train,y_pred_train))\n",
        "print('Adjusted R2 score', (1-(1-r2_score(y_train,y_pred_train))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1))))\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mTesting data R2 and Adjusted R2 Score\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('R2 score',r2_score(y_test,y_pred))\n",
        "print('Adjusted R2 score', (1-(1-r2_score(y_test,y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))))\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mCross-validation score and best params\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print(\"The best parameters is\", Reg_ridge.best_params_)\n",
        "print('cross-validation score', Reg_ridge.best_score_)\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mThe performance metrics\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('MAE',mean_absolute_error(y_test,y_pred))\n",
        "print('MSE',mean_squared_error(y_test,y_pred))\n",
        "print('RMSE',np.sqrt(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "TIq6oTLU7npL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the figure\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(y_pred)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No. of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vy1anIjc7qGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observations:** \n"
      ],
      "metadata": {
        "id": "lIhZqCjdOl21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Training data R2 and Adjusted R2 score is 0.8872978749437399\n",
        "0.8870312595752391 respectively.\n",
        "\n",
        "\n",
        "* Testing data R2 and Adjusted R2 score is 0.8849257240863323\n",
        "0.8841054390238112 respectively.\n",
        "\n",
        "\n",
        "* Cross-validation score and best params are as follows:\n",
        "\n",
        "   **The best parameters** is {'alpha': 0.001}\n",
        "\n",
        "   **cross-validation score** is 0.884838466969393\n",
        "\n",
        "\n",
        "* The performance metrics are as follows:\n",
        "\n",
        "     **MAE** 0.27379874378382013\n",
        "\n",
        "     **MSE** 0.11422278721950664\n",
        "\n",
        "     **RMSE** 0.3379686186904143"
      ],
      "metadata": {
        "id": "mze4mMVkOyRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply LassoRegression algorithm with hyperparameter tuning as step2\n",
        "\n",
        "\n",
        "# giving parameters\n",
        "parameters = {'alpha': [1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,2,3,4,5,8,12,15,18,21,25]}\n",
        "\n",
        "# we use gridsearchCV because the dataset is not that big so we use this not RandomizedSearchCV\n",
        "Reg_Lasso = GridSearchCV(Lasso(), parameters, cv=10)\n",
        "\n",
        "step2 = Reg_Lasso\n",
        "\n",
        "# make pipeline\n",
        "pipe3 = Pipeline([\n",
        "    ('step1',step1),\n",
        "    ('step2',step2)\n",
        "])\n",
        "\n",
        "# fit the pipeline on training dataset\n",
        "pipe3.fit(X_train,y_train)\n",
        "\n",
        "# predict the train and test dataset\n",
        "y_pred_train = pipe3.predict(X_train)\n",
        "y_pred = pipe3.predict(X_test)\n",
        "\n",
        "# display pipeline diagram\n",
        "display(pipe3)\n",
        "\n",
        "# Lasso Regression model all output scores\n",
        "print('\\033[1mTraining data R2 and Adjusted R2 Score\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('R2 score',r2_score(y_train,y_pred_train))\n",
        "print('Adjusted R2 score', (1-(1-r2_score(y_train,y_pred_train))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1))))\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mTesting data R2 and Adjusted R2 Score\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('R2 score',r2_score(y_test,y_pred))\n",
        "print('Adjusted R2 score', (1-(1-r2_score(y_test,y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))))\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mCross-validation score and best params\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print(\"The best parameters is\", Reg_Lasso.best_params_)\n",
        "print('cross-validation score', Reg_Lasso.best_score_)\n",
        "\n",
        "print('\\n')\n",
        "print('\\033[1mThe performance metrics\\033[0m')\n",
        "print('\\033[1m' + '-----------------------------------------' + '\\033[0m')\n",
        "print('MAE',mean_absolute_error(y_test,y_pred))\n",
        "print('MSE',mean_squared_error(y_test,y_pred))\n",
        "print('RMSE',np.sqrt(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "Kr1w2cb7745h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the figure\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.plot(y_pred)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No. of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U6An-a1T7826"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observations**"
      ],
      "metadata": {
        "id": "LHYn1QZXQfbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Training data R2 and Adjusted R2 Score as follows:\n",
        "\n",
        "    **R2 score** 0.8856772370433994\n",
        "\n",
        "    **Adjusted R2 score** 0.885406787790038\n",
        "\n",
        "\n",
        "* Testing data R2 and Adjusted R2 Score as follows:\n",
        "\n",
        "    **R2 score** 0.8824740403319331\n",
        "\n",
        "    **Adjusted R2 score** 0.8816362789086374\n",
        "\n",
        "\n",
        "* Cross-validation score and best params are as follows:\n",
        "\n",
        "    **The best parameters** is {'alpha': 1e-08}\n",
        "\n",
        "    **cross-validation score** 0.8832671645096054\n",
        "\n",
        "\n",
        "* The performance metrics are as follows:\n",
        "\n",
        "    **MAE** 0.275916310909462\n",
        "\n",
        "    **MSE** 0.11665632981262587\n",
        "\n",
        "    **RMSE** 0.3415498935918819"
      ],
      "metadata": {
        "id": "TYKzLWE5Qry4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The performance metrics of all three models (linear regression, Ridge regression, and Lasso regression) are very similar, with R2 scores ranging from 0.885 to 0.888 and RMSE values ranging from 0.338 to 0.342. However, Ridge regression and linear regression have slightly better R2 scores and lower RMSE values compared to Lasso regression.\n",
        "\n",
        "* Therefore, based on the performance metrics, both linear regression and Ridge regression appear to be good choices for this dataset. "
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}